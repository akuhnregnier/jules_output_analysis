{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/work/scratch-nopw/alexkr/multi_spinup6/jules_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(path):\n",
    "    return datetime.strptime(str(path).split(\".\")[-3], \"%Y%m%d\")\n",
    "\n",
    "\n",
    "def extract_spinup_index(fname):\n",
    "    if isinstance(fname, Path):\n",
    "        fname = str(fname.name)\n",
    "    return int(re.search(r\"SPINUP(\\d*)\", fname).group(1))\n",
    "\n",
    "\n",
    "def sort_key(path):\n",
    "    return extract_spinup_index(path), extract_date(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_files = sorted(DATA_DIR.glob(\"*SPINUP*dump*.nc\"), key=sort_key)\n",
    "dump_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(map(extract_date, dump_files))\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(map(lambda f: str(f).split(\".\")[-5], dump_files))\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_indices = [100, 200, 500]\n",
    "variable = \"cs\"\n",
    "plot_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for data_file, experiment, date in zip(\n",
    "    tqdm(dump_files, desc=\"Reading files\"), experiments, dates\n",
    "):\n",
    "    cube = iris.load_cube(str(data_file), constraint=variable)\n",
    "    for land_index in land_indices:\n",
    "        for i in range(4):\n",
    "            data_point = cube.data[i, ..., land_index]\n",
    "            assert not data_point.mask\n",
    "            plot_data[experiment][(land_index, i)].append((date, data_point.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitems = len(plot_data[experiments[0]])\n",
    "ncols = 4\n",
    "nrows = math.ceil(nitems / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(20, 15), constrained_layout=True)\n",
    "\n",
    "for experiment, single_plot_data in plot_data.items():\n",
    "    for ((key, values), ax) in zip(single_plot_data.items(), axes.ravel()):\n",
    "        ax.plot(*list(zip(*(values))), marker=\"o\", label=experiment)\n",
    "        ax.set_title(key)\n",
    "for ax in axes.ravel():\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counter = Counter(experiments)\n",
    "complete = sorted(\n",
    "    [exp for exp in exp_counter if exp_counter[exp] == max(exp_counter.values())],\n",
    "    key=extract_spinup_index,\n",
    ")\n",
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_masks = [None] * 4\n",
    "\n",
    "for data_file, experiment, date in zip(\n",
    "    tqdm(dump_files, desc=\"Creating shared mask\"), experiments, dates\n",
    "):\n",
    "    cube = iris.load_cube(str(data_file), constraint=variable)\n",
    "    if shared_masks[0] is None:\n",
    "        if isinstance(cube.data.mask, np.ndarray):\n",
    "            shared_masks = [cube.data.mask[i] for i in range(4)]\n",
    "        else:\n",
    "            assert not cube.data.mask\n",
    "            shared_masks = [\n",
    "                np.zeros_like(cube.data.data[i], dtype=np.bool_) for i in range(4)\n",
    "            ]\n",
    "    else:\n",
    "        for i in range(4):\n",
    "            if isinstance(cube.data.mask, np.ndarray):\n",
    "                shared_masks[i] |= cube.data.mask[i]\n",
    "            else:\n",
    "                assert not cube.data.mask\n",
    "    print(\"Masked elements:\", [np.sum(shared_masks[i]) for i in range(4)])\n",
    "\n",
    "concats = [defaultdict(list) for i in range(4)]\n",
    "for data_file, experiment, date in zip(\n",
    "    tqdm(dump_files, desc=\"Concatenating arrays\"), experiments, dates\n",
    "):\n",
    "    if experiment not in complete:\n",
    "        # Only handle complete experiments.\n",
    "        continue\n",
    "\n",
    "    cube = iris.load_cube(str(data_file), constraint=variable)\n",
    "    for (i, (shared_mask, concat)) in enumerate(zip(shared_masks, concats)):\n",
    "        concat[experiment].append(cube.data.data[i][~shared_mask])\n",
    "\n",
    "for concat in tqdm(concats, desc=\"Joining\"):\n",
    "    for experiment, arrs in concat.items():\n",
    "        concat[experiment] = np.vstack([arr[None] for arr in arrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = defaultdict(list)\n",
    "\n",
    "for index, concat in enumerate(concats):\n",
    "    for exp, comp_exp in zip(complete[1:], complete[:-1]):\n",
    "        diff = np.abs(concat[exp] - concat[comp_exp])\n",
    "        diff_data[index].append(\n",
    "            {\n",
    "                \"mean\": np.mean(diff),\n",
    "                \"std\": np.std(np.mean(diff, axis=1)),\n",
    "                \"max\": np.max(np.mean(diff, axis=1)),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = list(diff_data[0][0])\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    len(concats), len(measures), constrained_layout=True, figsize=(12, 8)\n",
    ")\n",
    "\n",
    "for ax_i, measure in enumerate(measures):\n",
    "    for i, ax in enumerate(axes[:, ax_i]):\n",
    "        ax.plot(complete[1:], [plot_dict[measure] for plot_dict in diff_data[i]])\n",
    "        ax.set_title(f\"$\\mathrm{{cs}}_\\mathrm{{{i + 1}}}$ {measure} of diffs\")\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
