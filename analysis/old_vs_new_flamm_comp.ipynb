{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from alepython import ale_plot\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from wildfires.analysis import cube_plotting\n",
    "from wildfires.data import GFEDv4, MonthlyDataset, homogenise_time_coordinate, regrid\n",
    "\n",
    "from jules_output_analysis.utils import (\n",
    "    collapse_cube_dim,\n",
    "    cube_1d_to_2d,\n",
    "    get_mm_data,\n",
    "    param_dict,\n",
    "    train_test_split_kwargs,\n",
    ")\n",
    "\n",
    "filterwarnings(\"ignore\", \".*divide by zero.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dirs = {\n",
    "    \"old\": Path(\"/work/scratch-nopw/alexkr/ignition3_5/jules_output\"),\n",
    "    \"new\": Path(\"/work/scratch-nopw/alexkr/antecedent3/jules_output\"),\n",
    "}\n",
    "for source_dir in source_dirs.values():\n",
    "    assert source_dir.is_dir()\n",
    "\n",
    "runs = {\n",
    "    \"old\": \"SPINUP6\",\n",
    "    \"new\": \"RUN1\",\n",
    "}\n",
    "\n",
    "names = {\n",
    "    \"old\": \"Ignition 3\",\n",
    "    \"new\": \"New Antec (Ig3)\",\n",
    "}\n",
    "\n",
    "pfts = (\n",
    "    \"Broadleaf trees\",\n",
    "    \"Needleleaf trees\",\n",
    "    \"C3 (temperate) grass\",\n",
    "    \"C4 (tropical) grass\",\n",
    "    \"Shrubs\",\n",
    ")\n",
    "\n",
    "soil_carbon_pools = (\"DPM\", \"RPM\", \"bio\", \"hum\")\n",
    "pfts = list(range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cubes = {\n",
    "    key: homogenise_time_coordinate(\n",
    "        iris.load(str(source_dir / f\"*{run_name}*Monthly*.nc\"))\n",
    "    ).concatenate()\n",
    "    for ((key, run_name), source_dir) in zip(runs.items(), source_dirs.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cube_names = set()\n",
    "for cubes in exp_cubes.values():\n",
    "    all_cube_names.update([cube.name() for cube in cubes])\n",
    "all_cube_names = sorted(all_cube_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube_name in tqdm(all_cube_names, desc=\"Plotting cubes\"):\n",
    "    for cubes, name in zip(exp_cubes.values(), names.values()):\n",
    "        for cube in cubes:\n",
    "            if cube.name() != cube_name:\n",
    "                continue\n",
    "\n",
    "            cube_2d = cube_1d_to_2d(cube[0])\n",
    "\n",
    "            assert len(cube_2d.shape) >= 2\n",
    "\n",
    "            if len(cube_2d.shape) == 2:\n",
    "                sel = slice(None)\n",
    "            else:\n",
    "                for indices in product(*(range(l) for l in cube_2d.shape[:-2])):\n",
    "                    sel = (*indices, slice(None), slice(None))\n",
    "            try:\n",
    "                fig = cube_plotting(cube_2d[sel], title=f\"{cube.name()} ({name})\")\n",
    "            except Exception as e:\n",
    "                print(\"cube:\", str(cube))\n",
    "                print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_cubes = {\n",
    "    key: cubes.extract_strict(iris.Constraint(name=\"Gridbox mean burnt area fraction\"))\n",
    "    for key, cubes in exp_cubes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ba_cube in zip(names.values(), ba_cubes.values()):\n",
    "    ba_2d = cube_1d_to_2d(ba_cube[10][0])\n",
    "    ba_2d.data.mask |= np.isnan(ba_2d.data)\n",
    "    title = f\"Mean BA {name}\"\n",
    "    fig = cube_plotting(\n",
    "        ba_2d,\n",
    "        fig=plt.figure(figsize=(6, 3), dpi=200),\n",
    "        boundaries=[0, 1e-11, 1e-10, 1e-9, 4e-9, 2e-8],\n",
    "        cmap=\"inferno\",\n",
    "        title=title,\n",
    "        extend=\"max\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose cubes to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cube_names = [\n",
    "    \"C in decomposable plant material, gridbox total\",\n",
    "    \"C in resistant plant material, gridbox total\",\n",
    "    \"Fractional cover of each surface type\",\n",
    "    \"Gridbox effective radiative temperature (assuming emissivity=1)\",\n",
    "    \"Gridbox gross primary productivity\",\n",
    "    \"Gridbox mean burnt area fraction\",\n",
    "    \"Gridbox precipitation rate\",\n",
    "    \"Gridbox unfrozen soil moisture as fraction of saturation\",\n",
    "    \"PFT Fraction of Absorbed Photosynthetically Active Radiation\",\n",
    "    \"PFT fuel build up\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_processed_cubes = {}\n",
    "proc_months = 150\n",
    "\n",
    "for key, cubes in exp_cubes.items():\n",
    "    processed_cubes = iris.cube.CubeList([])\n",
    "    for var in tqdm(proc_cube_names, desc=\"Processing cubes\"):\n",
    "        try:\n",
    "            ext_cube = cubes.extract_strict(iris.Constraint(name=var))\n",
    "        except iris.exceptions.ConstraintMismatchError:\n",
    "            continue\n",
    "\n",
    "        if len(ext_cube.shape) > 3:\n",
    "            ext_cube = collapse_cube_dim(ext_cube, 1)\n",
    "\n",
    "        # If needed, apply the same operation once again.\n",
    "        if len(ext_cube.shape) == 4:\n",
    "            ext_cube = collapse_cube_dim(ext_cube, 1)\n",
    "\n",
    "        assert len(ext_cube.shape) == 3\n",
    "\n",
    "        var_cube = cube_1d_to_2d(ext_cube)[-proc_months:]\n",
    "        processed_cubes.append(var_cube)\n",
    "    exp_processed_cubes[key] = processed_cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_proc_insts = defaultdict(list)\n",
    "\n",
    "for key, processed_cubes in exp_processed_cubes.items():\n",
    "    for proc_cube in tqdm(processed_cubes):\n",
    "        # Create a new Dataset for each cube.\n",
    "        proc_inst = type(\n",
    "            proc_cube.long_name.replace(\" \", \"\"),\n",
    "            (MonthlyDataset,),\n",
    "            {\n",
    "                \"__init__\": lambda self: None,\n",
    "                \"frequency\": \"monthly\",\n",
    "            },\n",
    "        )()\n",
    "        proc_inst.cubes = iris.cube.CubeList([proc_cube])\n",
    "        # Circumvent caching by including a random attribute.\n",
    "        proc_inst.cube.attributes[\"rand\"] = \"\".join(\n",
    "            random.choices(string.ascii_lowercase, k=100)\n",
    "        )\n",
    "\n",
    "        exp_proc_insts[key].append(\n",
    "            proc_inst.get_climatology_dataset(proc_inst.min_time, proc_inst.max_time)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_shifted_proc_cubes = defaultdict(list)\n",
    "exp_ba_cubes = {}\n",
    "\n",
    "for key, proc_insts in exp_proc_insts.items():\n",
    "    ba_cube = None\n",
    "\n",
    "    for proc_inst in proc_insts:\n",
    "        if \"burnt area\" in proc_inst.cube.long_name:\n",
    "            exp_ba_cubes[key] = proc_inst.cube\n",
    "            continue\n",
    "        exp_shifted_proc_cubes[key].append(proc_inst.cube)\n",
    "        for shift in (1, 3, 6, 9):\n",
    "            # XXX: Overly simplistic np.roll() implementation!!\n",
    "            c2 = proc_inst.cube.copy()\n",
    "            c2.data = np.roll(proc_inst.cube.data, shift, axis=0)\n",
    "            c2.long_name = c2.long_name + f\"({shift})\"\n",
    "            c2.var_name = None\n",
    "            c2.short_name = None\n",
    "\n",
    "            exp_shifted_proc_cubes[key].append(c2)\n",
    "\n",
    "    assert exp_ba_cubes[key] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, shifted_proc_cubes in exp_shifted_proc_cubes.items():\n",
    "    plt.figure(figsize=(5, 3), dpi=150)\n",
    "    for i in np.array([0, 1, 2]) + 35:\n",
    "        cube = shifted_proc_cubes[i]\n",
    "        print(cube.coord(\"month_number\").points)\n",
    "        plt.plot(\n",
    "            cube.coord(\"month_number\").points,\n",
    "            cube.data[:, 72, 110],\n",
    "            label=cube.name(),\n",
    "            alpha=0.9,\n",
    "            marker=\"x\",\n",
    "        )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_masks = [\n",
    "    ba_cube.data.mask | (ba_cube.data.data > 1e-5) for ba_cube in exp_ba_cubes.values()\n",
    "]\n",
    "master_mask = reduce(np.logical_or, master_masks)\n",
    "_ = cube_plotting(master_mask, title=\"Mask\", colorbar_kwargs={\"label\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_endog_data = {}\n",
    "exp_exog_data = {}\n",
    "\n",
    "for key, ba_cube in exp_ba_cubes.items():\n",
    "    exp_endog_data[key] = pd.Series(ba_cube.data.data[~master_mask])\n",
    "    exp_endog_data[key].name = \"burnt area\"\n",
    "\n",
    "    exog_dict = {}\n",
    "    for cube in exp_shifted_proc_cubes[key]:\n",
    "        exog_dict[cube.long_name] = cube.data.data[~master_mask]\n",
    "\n",
    "    exp_exog_data[key] = pd.DataFrame(exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_mapping = {\n",
    "    \"Gridbox\": \"\",\n",
    "    \"precipitation\": \"precip\",\n",
    "    \"soil carbon in each pool\": \"soil pool carbon\",\n",
    "    \"surface\": \"surf\",\n",
    "    \"evapotranspiration\": \"evapot\",\n",
    "    \"from soil moisture store\": \"soil moist\",\n",
    "    \"temperature\": \"temp\",\n",
    "    \"unfrozen moisture content of each soil layer as a fraction of saturation\": \"unfrozen moist soil layer / sat\",\n",
    "    \"gross primary productivity\": \"gpp\",\n",
    "    \"net primary productivity\": \"npp\",\n",
    "    \"soil moisture availability factor (beta)\": \"soil moist avail fact\",\n",
    "    \"total carbon content of the vegetation at the end of model timestep\": \"total veg C end timestep\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_columns(df):\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        for old, new in shorten_mapping.items():\n",
    "            col = col.replace(old, new)\n",
    "        col = col.strip()\n",
    "        new_cols.append(col)\n",
    "    df.columns = new_cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(shorten_columns, exp_exog_data.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the BA data so it has higher magnitudes\n",
    "\n",
    "This seems to be required by the RF algorithm in order to make any predictions at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_endog_data = {\n",
    "    key: endog_data / np.max(endog_data) for key, endog_data in exp_endog_data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model_data = {}\n",
    "for key in runs:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        exp_exog_data[key], exp_endog_data[key], **train_test_split_kwargs\n",
    "    )\n",
    "    exp_model_data[key] = dict(\n",
    "        X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_models = {key: RandomForestRegressor(**param_dict) for key in runs}\n",
    "for key, model in exp_models.items():\n",
    "    model.n_jobs = 3\n",
    "    model.fit(exp_model_data[key][\"X_train\"], exp_model_data[key][\"y_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in exp_models.items():\n",
    "    exp_model_data[key][\"y_train_pred\"] = model.predict(exp_model_data[key][\"X_train\"])\n",
    "    exp_model_data[key][\"y_test_pred\"] = model.predict(exp_model_data[key][\"X_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in runs:\n",
    "    print(key)\n",
    "    print(\n",
    "        \"train:\",\n",
    "        r2_score(\n",
    "            y_true=exp_model_data[key][\"y_train\"],\n",
    "            y_pred=exp_model_data[key][\"y_train_pred\"],\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"val:\",\n",
    "        r2_score(\n",
    "            y_true=exp_model_data[key][\"y_test\"],\n",
    "            y_pred=exp_model_data[key][\"y_test_pred\"],\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cube_plotting(\n",
    "    get_mm_data(y_test.values, master_mask, \"val\"),\n",
    "    boundaries=[0, 1e-3, 1e-2, 0.05, 0.2, 0.5],\n",
    "    cmap=\"inferno\",\n",
    "    fig=plt.figure(figsize=(7, 3.2), dpi=150),\n",
    "    colorbar_kwargs=dict(label=\"burnt area (scaled)\"),\n",
    "    title=\"Validation Observations\",\n",
    "    extend=\"neither\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cube_plotting(\n",
    "    get_mm_data(y_test_pred, master_mask, \"val\"),\n",
    "    boundaries=[0, 1e-3, 1e-2, 0.05, 0.2, 0.5],\n",
    "    cmap=\"inferno\",\n",
    "    fig=plt.figure(figsize=(7, 3.2), dpi=150),\n",
    "    colorbar_kwargs=dict(label=\"burnt area (scaled)\"),\n",
    "    title=\"Validation Predictions\",\n",
    "    extend=\"neither\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=250)\n",
    "plt.hexbin(y_train, y_train_pred, bins=\"log\")\n",
    "plt.xlabel(\"observed BA (train)\")\n",
    "_ = plt.ylabel(\"predicted BA (train)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=250)\n",
    "plt.hexbin(y_test, y_test_pred, bins=\"log\")\n",
    "plt.xlabel(\"observed BA (test)\")\n",
    "_ = plt.ylabel(\"predicted BA (test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in exp_models.items():\n",
    "    ind_trees_gini = pd.DataFrame(\n",
    "        [tree.feature_importances_ for tree in model],\n",
    "        columns=exp_model_data[key][\"X_train\"].columns,\n",
    "    )\n",
    "    mean_importances = ind_trees_gini.mean().sort_values(ascending=False)\n",
    "    ind_trees_gini = ind_trees_gini.reindex(mean_importances.index, axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 4), dpi=170)\n",
    "\n",
    "    N_col = 18\n",
    "\n",
    "    sns.boxplot(data=ind_trees_gini.iloc[:, :N_col], ax=ax)\n",
    "    ax.set(ylabel=f\"Gini Importance\\n\")\n",
    "    ax.set_title(names[key])\n",
    "    _ = plt.setp(ax.xaxis.get_majorticklabels(), rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in exp_models.items():\n",
    "    for feature in tqdm(exp_model_data[key][\"X_train\"].columns, desc=\"1D ALE plots\"):\n",
    "        fig, axes = ale_plot(\n",
    "            model,\n",
    "            exp_model_data[key][\"X_train\"],\n",
    "            feature,\n",
    "            bins=20,\n",
    "            fig=plt.figure(figsize=(5.5, 2), dpi=150),\n",
    "            quantile_axis=True,\n",
    "            monte_carlo=True,\n",
    "            monte_carlo_rep=10,\n",
    "            monte_carlo_ratio=0.2,\n",
    "        )\n",
    "        axes[\"ale\"].set_title(f\"{feature}\\n({names[key]})\")\n",
    "        plt.setp(axes[\"ale\"].xaxis.get_majorticklabels(), rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GFED4 BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_ba = GFEDv4()\n",
    "\n",
    "gfed_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_cubes[0].coord(\"time\").cell(0).point, processed_cubes[0].coord(\"time\").cell(\n",
    "    -1\n",
    ").point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_ba.limit_months(\n",
    "    processed_cubes[0].coord(\"time\").cell(0).point,\n",
    "    processed_cubes[0].coord(\"time\").cell(-1).point,\n",
    ")\n",
    "\n",
    "gfed_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_gfed_ba = gfed_ba.get_climatology_dataset(gfed_ba.min_time, gfed_ba.max_time)\n",
    "clim_gfed_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_gfed_ba.cube.coord(\"month_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regrid GFED4 to N96e grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_gfed_ba.cube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_gfed_ba.cube.coord(\"latitude\").bounds = None\n",
    "clim_gfed_ba.cube.coord(\"latitude\").guess_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gfed_ba_cube = regrid(\n",
    "    clim_gfed_ba.cube,\n",
    "    new_latitudes=shifted_proc_cubes[0].coord(\"latitude\"),\n",
    "    new_longitudes=shifted_proc_cubes[0].coord(\"longitude\"),\n",
    "    area_weighted=True,\n",
    "    verbose=True,\n",
    ")\n",
    "reg_gfed_ba_cube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_plot_gfed_cube = reg_gfed_ba_cube.copy()\n",
    "reg_plot_gfed_cube.data.mask = master_mask\n",
    "fig = cube_plotting(\n",
    "    reg_plot_gfed_cube / (30 * 24 * 60 * 60),\n",
    "    colorbar_kwargs=dict(label=r\"$\\mathrm{s}^{-1}$\"),\n",
    "    fig=plt.figure(figsize=(6, 3), dpi=200),\n",
    "    boundaries=[0, 1e-11, 1e-10, 1e-9, 4e-9, 2e-8],\n",
    "    cmap=\"inferno\",\n",
    "    title=\"Mean GFED4 BA\",\n",
    "    extend=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_endog_data = pd.Series(reg_gfed_ba_cube.data.data[~master_mask])\n",
    "gfed_endog_data.name = \"GFED4 burnt area\"\n",
    "gfed_endog_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing GFED4 and JULES BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(gfed_endog_data.values, endog_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(gfed_endog_data, endog_data, bins=\"log\")\n",
    "plt.xlabel(\"GFED4\")\n",
    "_ = plt.ylabel(\"JULES BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_X_train, gfed_X_test, gfed_y_train, gfed_y_test = train_test_split(\n",
    "    exog_data, gfed_endog_data, **train_test_split_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_model = RandomForestRegressor(**param_dict)\n",
    "gfed_model.n_jobs = 3\n",
    "gfed_model.fit(gfed_X_train, gfed_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_y_train_pred = gfed_model.predict(gfed_X_train)\n",
    "gfed_y_test_pred = gfed_model.predict(gfed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:\", r2_score(gfed_y_train_pred, gfed_y_train))\n",
    "print(\"val:\", r2_score(gfed_y_test_pred, gfed_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gfed_y_test.values)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cube_plotting(\n",
    "    get_mm_data(gfed_y_test.values, master_mask, \"val\"),\n",
    "    boundaries=[0, 1e-3, 1e-2, 0.05, 0.2, 0.5],\n",
    "    cmap=\"inferno\",\n",
    "    fig=plt.figure(figsize=(7, 3.2), dpi=150),\n",
    "    colorbar_kwargs=dict(label=\"burnt area (scaled)\"),\n",
    "    title=\"GFED Validation Observations\",\n",
    "    extend=\"neither\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cube_plotting(\n",
    "    get_mm_data(gfed_y_test_pred, master_mask, \"val\"),\n",
    "    boundaries=[0, 1e-3, 1e-2, 0.05, 0.2, 0.5],\n",
    "    cmap=\"inferno\",\n",
    "    fig=plt.figure(figsize=(7, 3.2), dpi=150),\n",
    "    colorbar_kwargs=dict(label=\"burnt area (scaled)\"),\n",
    "    title=\"GFED Validation Predictions\",\n",
    "    extend=\"neither\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=250)\n",
    "plt.hexbin(gfed_y_train, gfed_y_train_pred, bins=\"log\")\n",
    "plt.xlabel(\"observed BA (train)\")\n",
    "_ = plt.ylabel(\"predicted BA (train)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=250)\n",
    "plt.hexbin(gfed_y_test, gfed_y_test_pred, bins=\"log\")\n",
    "plt.xlabel(\"observed BA (test)\")\n",
    "_ = plt.ylabel(\"predicted BA (test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_ind_trees_gini = pd.DataFrame(\n",
    "    [tree.feature_importances_ for tree in gfed_model],\n",
    "    columns=gfed_X_train.columns,\n",
    ")\n",
    "gfed_mean_importances = gfed_ind_trees_gini.mean().sort_values(ascending=False)\n",
    "gfed_ind_trees_gini = gfed_ind_trees_gini.reindex(gfed_mean_importances.index, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), dpi=170)\n",
    "\n",
    "N_col = 18\n",
    "\n",
    "sns.boxplot(data=gfed_ind_trees_gini.iloc[:, :N_col], ax=ax)\n",
    "ax.set(\n",
    "    # title=\"Gini Importances\",\n",
    "    ylabel=\"Gini Importance\\n\"\n",
    ")\n",
    "_ = plt.setp(ax.xaxis.get_majorticklabels(), rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_ind_trees_gini = pd.DataFrame(\n",
    "    [tree.feature_importances_ for tree in gfed_model],\n",
    "    columns=gfed_X_train.columns,\n",
    ")\n",
    "gfed_mean_importances = gfed_ind_trees_gini.mean().sort_values(ascending=False)\n",
    "gfed_ind_trees_gini = gfed_ind_trees_gini.reindex(gfed_mean_importances.index, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), dpi=170)\n",
    "\n",
    "N_col = 30\n",
    "\n",
    "sns.boxplot(data=gfed_ind_trees_gini.iloc[:, :N_col], ax=ax)\n",
    "ax.set(\n",
    "    # title=\"Gini Importances\",\n",
    "    ylabel=\"Gini Importance\\n\"\n",
    ")\n",
    "_ = plt.setp(ax.xaxis.get_majorticklabels(), rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in tqdm(gfed_X_train.columns, desc=\"1D ALE plots\"):\n",
    "    fig, axes = ale_plot(\n",
    "        gfed_model,\n",
    "        gfed_X_train,\n",
    "        feature,\n",
    "        bins=20,\n",
    "        fig=plt.figure(figsize=(5.5, 2), dpi=150),\n",
    "        quantile_axis=True,\n",
    "        monte_carlo=True,\n",
    "        monte_carlo_rep=10,\n",
    "        monte_carlo_ratio=0.2,\n",
    "    )\n",
    "    plt.setp(axes[\"ale\"].xaxis.get_majorticklabels(), rotation=60, ha=\"right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
