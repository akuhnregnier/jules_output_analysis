{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import dask.array as da\n",
    "import iris\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from iris.coord_categorisation import add_day_of_year, add_month_number\n",
    "from python_inferno.utils import exponential_average, temporal_nearest_neighbour_interp\n",
    "from wildfires.configuration import DATA_DIR\n",
    "from wildfires.utils import match_shape\n",
    "\n",
    "from jules_output_analysis.data import (\n",
    "    cube_1d_to_2d,\n",
    "    get_n96e_land_mask,\n",
    "    load_lat_lon_coords,\n",
    "    regrid_to_n96e,\n",
    ")\n",
    "from jules_output_analysis.utils import PFTs, pft_acronyms, pft_names\n",
    "\n",
    "filterwarnings(\"ignore\", \".*divide by zero.*\")\n",
    "filterwarnings(\"ignore\", \".*invalid units.*\")\n",
    "filterwarnings(\"ignore\", \".*may not be fully.*\")\n",
    "filterwarnings(\"ignore\", \".*axes.*\")\n",
    "filterwarnings(\"ignore\")\n",
    "mpl.rc_file(\"matplotlibrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = str(Path(\"~/tmp/climatology5_c.nc\").expanduser())\n",
    "lat_coord, lon_coord = load_lat_lon_coords(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(x, points):\n",
    "    \"\"\"Get element of `points` that is closest to x.\"\"\"\n",
    "    diffs = np.abs(points - x)\n",
    "    return points[np.argmin(diffs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c.name() for c in iris.load_raw(source_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_climatology(cube):\n",
    "    avg_cube = cube.aggregated_by(\"month_number\", iris.analysis.MEAN)\n",
    "\n",
    "    # Check that the points are correctly ordered.\n",
    "    month_number_points = avg_cube.coord(\"month_number\").points\n",
    "    assert np.all(np.sort(month_number_points) == month_number_points)\n",
    "\n",
    "    # Save final temporal coord.\n",
    "    temp_coord = iris.coords.DimCoord.from_coord(avg_cube.coord(\"month_number\"))\n",
    "\n",
    "    # Remove all other temporal coordinates.\n",
    "    for coord in avg_cube.coords(dimensions=0):\n",
    "        avg_cube.remove_coord(coord)\n",
    "\n",
    "    # Add the stored coord.\n",
    "    avg_cube.add_dim_coord(temp_coord, 0)\n",
    "\n",
    "    assert len(avg_cube.coords(dimensions=0)) == 1\n",
    "\n",
    "    return avg_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_climatology(cube):\n",
    "    avg_cube = cube.aggregated_by(\"day_of_year\", iris.analysis.MEAN)\n",
    "\n",
    "    # Check that the points are correctly ordered.\n",
    "    points = avg_cube.coord(\"day_of_year\").points\n",
    "    assert np.all(np.sort(points) == points)\n",
    "\n",
    "    # Save final temporal coord.\n",
    "    temp_coord = iris.coords.DimCoord.from_coord(avg_cube.coord(\"day_of_year\"))\n",
    "\n",
    "    # Remove all other temporal coordinates.\n",
    "    for coord in avg_cube.coords(dimensions=0):\n",
    "        avg_cube.remove_coord(coord)\n",
    "\n",
    "    # Add the stored coord.\n",
    "    avg_cube.add_dim_coord(temp_coord, 0)\n",
    "\n",
    "    assert len(avg_cube.coords(dimensions=0)) == 1\n",
    "\n",
    "    return avg_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_dim_check(cube_2d):\n",
    "    if (len(cube_2d.shape) > 2) and cube_2d.shape[-3] == 13:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name, data, frac_cube=None):\n",
    "    if frac_cube is None and name != \"frac\":\n",
    "        raise RuntimeError(\n",
    "            \"We should only miss `frac_cube` if 'frac' itself is being loaded.\"\n",
    "        )\n",
    "\n",
    "    data[\"raw_cube\"] = iris.load_cube(source_file, constraint=data[\"var_name\"])\n",
    "    add_month_number(data[\"raw_cube\"], \"time\")\n",
    "    add_day_of_year(data[\"raw_cube\"], \"time\")\n",
    "\n",
    "    N = len(data[\"raw_cube\"].shape)\n",
    "    if not data[\"raw_cube\"].coords(\"latitude\"):\n",
    "        data[\"raw_cube\"].add_aux_coord(\n",
    "            lat_coord,\n",
    "            (N - 2, N - 1),\n",
    "        )\n",
    "    if not data[\"raw_cube\"].coords(\"longitude\"):\n",
    "        data[\"raw_cube\"].add_aux_coord(\n",
    "            lon_coord,\n",
    "            (N - 2, N - 1),\n",
    "        )\n",
    "\n",
    "    if frac_cube is not None and frac_dim_check(data[\"raw_cube\"]):\n",
    "        assert frac_cube[..., :13, :, :].shape == data[\"raw_cube\"].shape\n",
    "        assert frac_cube.shape[-3] == 17\n",
    "\n",
    "        # 'Select' the first PFT in order to have a template for the resulting cube.\n",
    "        # Fill this template with the actual PFT-weighted mean.\n",
    "        data[\"w_frac_raw_cube\"] = data[\"raw_cube\"][..., 0, :, :].copy(\n",
    "            data=da.sum(\n",
    "                frac_cube[..., :13, :, :].lazy_data() * data[\"raw_cube\"].lazy_data(),\n",
    "                axis=-3,\n",
    "            )\n",
    "            / da.sum(frac_cube[..., :13, :, :].lazy_data(), axis=-3)\n",
    "        )\n",
    "\n",
    "    for proc_name in (\n",
    "        \"raw_cube\",\n",
    "        *((\"w_frac_raw_cube\",) if \"w_frac_raw_cube\" in data else ()),\n",
    "    ):\n",
    "        new_name = proc_name.replace(\"raw_cube\", \"avg_cube\")\n",
    "        data[new_name] = data[proc_name].collapsed(\"time\", iris.analysis.MEAN)\n",
    "        data[f\"mon_{new_name}\"] = monthly_climatology(data[proc_name])\n",
    "        data[f\"day_{new_name}\"] = daily_climatology(data[proc_name])\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    for avg_name, check_n in (\n",
    "        (\"avg_cube\", 2),\n",
    "        # (\"mon_avg_cube\", 3),\n",
    "        # (\"day_avg_cube\", 3),\n",
    "        *(\n",
    "            (\n",
    "                (\"w_frac_avg_cube\", 2),\n",
    "                # (\"mon_w_frac_vg_cube\", 3),\n",
    "                # (\"day_w_frac_vg_cube\", 3),\n",
    "            )\n",
    "            if \"w_frac_raw_cube\" in data\n",
    "            else ()\n",
    "        ),\n",
    "    ):\n",
    "        N = len(data[avg_name].shape)\n",
    "        assert N >= check_n\n",
    "\n",
    "        data[f\"{avg_name}_2d\"] = cube_1d_to_2d(data[avg_name])\n",
    "\n",
    "        print(data[avg_name].shape, data[f\"{avg_name}_2d\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\n",
    "    \"pft_lai\": dict(\n",
    "        var_name=\"PFT leaf area index\",\n",
    "        label=\"LAI (1)\",\n",
    "        name=\"JULES LAI\",\n",
    "    ),\n",
    "    \"pft_fapar\": dict(\n",
    "        var_name=\"PFT Fraction of Absorbed Photosynthetically Active Radiation\",\n",
    "        label=\"FAPAR (1)\",\n",
    "        name=\"JULES FAPAR\",\n",
    "    ),\n",
    "    \"frac\": dict(\n",
    "        var_name=\"Fractional cover of each surface type\",\n",
    "        label=\"1\",\n",
    "        name=\"JULES Frac\",\n",
    "    ),\n",
    "    \"pft_gpp\": dict(\n",
    "        var_name=\"PFT gross primary productivity\",\n",
    "        label=\"GPP\",\n",
    "        name=\"JULES GPP\",\n",
    "    ),\n",
    "    \"pft_npp\": dict(\n",
    "        var_name=\"PFT net primary productivity prior to N limitation\",\n",
    "        label=\"NPP\",\n",
    "        name=\"JULES NPP\",\n",
    "    ),\n",
    "    \"ba\": dict(\n",
    "        var_name=\"Gridbox mean burnt area fraction\",\n",
    "        label=\"BA\",\n",
    "        name=\"JULES BA\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Load frac data first.\n",
    "load_data(\"frac\", variables[\"frac\"])\n",
    "\n",
    "for name, data in variables.items():\n",
    "    if name == \"frac\":\n",
    "        continue\n",
    "\n",
    "    load_data(name, data, variables[\"frac\"][\"raw_cube\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, val in variables[\"pft_lai\"].items():\n",
    "    if hasattr(val, \"shape\"):\n",
    "        print(name, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_variables = dict(\n",
    "    LAI=dict(\n",
    "        filename=Path(DATA_DIR) / \"LAI_climatology.nc\",\n",
    "    ),\n",
    "    FAPAR=dict(\n",
    "        filename=Path(DATA_DIR) / \"FAPAR_climatology.nc\",\n",
    "    ),\n",
    "    BA=dict(\n",
    "        filename=Path(DATA_DIR) / \"GFED4_climatology.nc\",\n",
    "    ),\n",
    ")\n",
    "for name, data in ref_variables.items():\n",
    "    cube_2d = regrid_to_n96e(iris.load_cube(str(data[\"filename\"])))\n",
    "    cube_2d.data.mask |= match_shape(\n",
    "        ~get_n96e_land_mask(),\n",
    "        cube_2d.shape,\n",
    "    )\n",
    "    data[\"mon_avg_cube_2d\"] = cube_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lat_lon(cube, latitude, longitude):\n",
    "    return cube.extract(\n",
    "        constraint=iris.Constraint(\n",
    "            latitude=lambda cell: latitude - 1e-8 < cell.point < latitude + 1e-8\n",
    "        )\n",
    "    ).extract(\n",
    "        constraint=iris.Constraint(\n",
    "            longitude=lambda cell: longitude - 1e-8 < cell.point < longitude + 1e-8\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = get_closest(8, lat_coord.points.ravel())\n",
    "longitude = get_closest(18, lon_coord.points.ravel())\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "ax.plot(longitude, latitude, linestyle=\"\", marker=\"x\", transform=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "\n",
    "for name, data in variables.items():\n",
    "    if \"pft\" not in name:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(14, 7))\n",
    "    axes = axes.ravel()\n",
    "    for ax in axes[-2:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for (i, (ax, pft_name, pft_acr)) in enumerate(\n",
    "        zip(axes, pft_names[PFTs.VEG13], pft_acronyms[PFTs.VEG13])\n",
    "    ):\n",
    "        ax.set_title(f\"{pft_name} ({pft_acr})\")\n",
    "\n",
    "        lines = []\n",
    "        labels = []\n",
    "\n",
    "        for plot_ax, cube, label, c in (\n",
    "            (ax, data[\"day_avg_cube\"], name, \"C0\"),\n",
    "            (ax.twinx(), variables[\"frac\"][\"day_avg_cube\"], \"frac\", \"C1\"),\n",
    "        ):\n",
    "            plot_ax.plot(\n",
    "                cube.coord(\"day_of_year\").points,\n",
    "                extract_lat_lon(\n",
    "                    cube[..., i, 0, :],\n",
    "                    latitude,\n",
    "                    longitude,\n",
    "                )[:].data,\n",
    "                linestyle=\"--\",\n",
    "                marker=\"x\",\n",
    "                alpha=0.2,\n",
    "                label=label,\n",
    "                c=c,\n",
    "            )\n",
    "            new_lines, new_labels = plot_ax.get_legend_handles_labels()\n",
    "            lines.extend(new_lines)\n",
    "            labels.extend(new_labels)\n",
    "\n",
    "        ax.legend(lines, labels)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.suptitle(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for olat, olon in (\n",
    "    [8, 18],\n",
    "    [-18.6, 131.5],\n",
    "    [-0.3, 20.6],\n",
    "    [-20, 307],\n",
    "):\n",
    "    latitude = get_closest(olat, lat_coord.points.ravel())\n",
    "    longitude = get_closest(olon, lon_coord.points.ravel())\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "    ax.plot(longitude, latitude, linestyle=\"\", marker=\"x\", transform=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "    ax.coastlines()\n",
    "    ax.set_title(f\"lat={latitude}, lon={longitude}\")\n",
    "\n",
    "    plot_vars = {name: data for name, data in variables.items() if name != \"frac\"}\n",
    "\n",
    "    N = len(plot_vars)\n",
    "    ncols = math.ceil(N ** 0.5)\n",
    "    nrows = math.ceil(N / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols, figsize=np.array([2.5, 3]) * np.array([ncols, nrows])\n",
    "    )\n",
    "    axes = axes.ravel()\n",
    "    if ncols * nrows > N:\n",
    "        for ax in axes[-(ncols * nrows - N) :]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    for (ax, (name, data)) in zip(axes, plot_vars.items()):\n",
    "        ax.set_title(name)\n",
    "\n",
    "        xs = data[\"day_avg_cube\"].coord(\"day_of_year\").points\n",
    "        points = extract_lat_lon(\n",
    "            data.get(\"day_w_frac_avg_cube\", data[\"day_avg_cube\"])[..., 0, :],\n",
    "            latitude,\n",
    "            longitude,\n",
    "        ).data\n",
    "        plot_kwargs = dict(linestyle=\"--\", marker=\"x\", alpha=0.2)\n",
    "\n",
    "        ax.plot(xs, points, label=\"JULES\", **plot_kwargs)\n",
    "\n",
    "        # Calculate the antecedent fuel build-up metric.\n",
    "        # This uses the fact that we are using data that is exported by the model every 4\n",
    "        # timesteps.\n",
    "        # Repeat the averaging procedure in order to reach convergence for a more\n",
    "        # realistic depiction of the averaged parameter.\n",
    "        if name != \"ba\":\n",
    "            for alpha, label in (\n",
    "                (4.6e-4, \"\"),\n",
    "                (1e-4, \"*\"),\n",
    "                (1e-3, \"+\"),\n",
    "            ):\n",
    "                ax.plot(\n",
    "                    xs,\n",
    "                    exponential_average(\n",
    "                        temporal_nearest_neighbour_interp(points, 4),\n",
    "                        alpha,\n",
    "                        repetitions=10,\n",
    "                    )[::4],\n",
    "                    label=f\"Antec JULES{label}\",\n",
    "                    **plot_kwargs,\n",
    "                )\n",
    "\n",
    "        obs_name = name.split(\"_\")[-1].upper()\n",
    "\n",
    "        if obs_name in ref_variables:\n",
    "            ax.plot(\n",
    "                (365 / 12) * (0.5 + np.arange(12)),\n",
    "                extract_lat_lon(\n",
    "                    ref_variables[obs_name][\"mon_avg_cube_2d\"],\n",
    "                    latitude,\n",
    "                    longitude,\n",
    "                ).data\n",
    "                / (30 * 24 * 60 * 60 if name == \"ba\" else 1),\n",
    "                linestyle=\"-.\",\n",
    "                marker=\"o\",\n",
    "                alpha=0.6,\n",
    "                label=\"Obs\",\n",
    "            )\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "    fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
